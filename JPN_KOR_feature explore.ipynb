{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziru/anaconda/lib/python2.7/site-packages/matplotlib/__init__.py:913: UserWarning: axes.color_cycle is deprecated and replaced with axes.prop_cycle; please use the latter.\n",
      "  warnings.warn(self.msg_depr % (key, alt_key))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import prework as pwk\n",
    "import string\n",
    "from time import time\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score, KFold\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "import statsmodels as sm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import recall_score, accuracy_score, precision_score, roc_auc_score\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import nltk\n",
    "from gensim.models.doc2vec import LabeledSentence, Doc2Vec, TaggedDocument\n",
    "from gensim.utils import simple_preprocess\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sbn\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "stdout = sys.stdout\n",
    "\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf-8')\n",
    "\n",
    "sys.stdout = stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "spc_nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add sytactic features from pickle file (syntactic feature generation takes a long time, so pickling is here to save some time)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_0 = pd.read_pickle('data/pickles/final_df_20180111.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_0 = df_0.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'doc_id|||path|||author_code|||essay_content|||label|||DT_max_dp_cnts|||DT_archs|||DT_ROOT_idx|||DT_pass_cnt|||DT_mark_cnt|||POS_adjv_body|||DT_pos|||DT_pos_join|||DT_archs_join|||unique_lemma|||avg_stc_length|||total_stc|||POS_adjv_repeat|||POS_adjv_repeat_sum|||doc2vec_lm_token'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'|||'.join(df_0.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate lexical features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df_0['unique_lemma'] = df_0['essay_content'].apply(lambda x: len(set([token.lemma_ for token in spc_nlp(x.decode('utf-8')) if token.is_punct==False])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df_0['avg_stc_length'] = df_0['essay_content'].apply(lambda x: np.mean([len(s) for s in spc_nlp(x.decode('utf-8')).sents]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df_0['total_stc'] = df_0['essay_content'].apply(lambda x: len([s for s in spc_nlp(x.decode('utf-8')).sents]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#'|||'.join(df_0.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the final dataframe to a pickle file as a backup\n",
    "#df_0.to_pickle('final_df_20180111.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>path</th>\n",
       "      <th>author_code</th>\n",
       "      <th>essay_content</th>\n",
       "      <th>label</th>\n",
       "      <th>DT_max_dp_cnts</th>\n",
       "      <th>DT_archs</th>\n",
       "      <th>DT_ROOT_idx</th>\n",
       "      <th>DT_pass_cnt</th>\n",
       "      <th>DT_mark_cnt</th>\n",
       "      <th>POS_adjv_body</th>\n",
       "      <th>DT_pos</th>\n",
       "      <th>DT_pos_join</th>\n",
       "      <th>DT_archs_join</th>\n",
       "      <th>unique_lemma</th>\n",
       "      <th>avg_stc_length</th>\n",
       "      <th>total_stc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>data/ICNALE/Unmerged_classified/ICNALE_W_CHN_A...</td>\n",
       "      <td>W_CHN_PTJ0_021_A2_0.txt</td>\n",
       "      <td>﻿I agree that it is important for college stud...</td>\n",
       "      <td>CHN</td>\n",
       "      <td>[4, 6, 6, 8, 8, 5, 4, 6, 8, 4, 5, 7, 6]</td>\n",
       "      <td>[nsubj ROOT mark nsubj ccomp acomp mark compou...</td>\n",
       "      <td>[1, 9, 3, 16, 8, 8, 1, 3, 7, 1, 11, 2, 4]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[2, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[apart, nowadays, large, well, many, when, the...</td>\n",
       "      <td>[NOUN VERB ADP PRON VERB ADJ ADP NOUN NOUN PAR...</td>\n",
       "      <td>NOUN VERB ADP PRON VERB ADJ ADP NOUN NOUN PART...</td>\n",
       "      <td>nsubj ROOT mark nsubj ccomp acomp mark compoun...</td>\n",
       "      <td>94</td>\n",
       "      <td>19.538462</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>data/ICNALE/Unmerged_classified/ICNALE_W_CHN_A...</td>\n",
       "      <td>W_CHN_PTJ0_022_A2_0.txt</td>\n",
       "      <td>﻿In the last years, college students taking a ...</td>\n",
       "      <td>CHN</td>\n",
       "      <td>[7, 4, 4, 3, 5, 5, 5, 5, 4, 6, 6, 7, 8, 9]</td>\n",
       "      <td>[aux det amod npadvmod punct compound nsubj ac...</td>\n",
       "      <td>[13, 2, 2, 1, 3, 6, 8, 5, 2, 3, 2, 4, 11, 4]</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1]</td>\n",
       "      <td>[0, 2, 0, 0, 1, 0, 1, 0, 0, 2, 0, 0, 1, 0]</td>\n",
       "      <td>[last, very, big, many, firstly, most, importa...</td>\n",
       "      <td>[VERB DET ADJ NOUN PUNCT NOUN NOUN VERB DET AD...</td>\n",
       "      <td>VERB DET ADJ NOUN PUNCT NOUN NOUN VERB DET ADJ...</td>\n",
       "      <td>aux det amod npadvmod punct compound nsubj acl...</td>\n",
       "      <td>100</td>\n",
       "      <td>16.714286</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_id                                               path  \\\n",
       "0       1  data/ICNALE/Unmerged_classified/ICNALE_W_CHN_A...   \n",
       "1       2  data/ICNALE/Unmerged_classified/ICNALE_W_CHN_A...   \n",
       "\n",
       "               author_code                                      essay_content  \\\n",
       "0  W_CHN_PTJ0_021_A2_0.txt  ﻿I agree that it is important for college stud...   \n",
       "1  W_CHN_PTJ0_022_A2_0.txt  ﻿In the last years, college students taking a ...   \n",
       "\n",
       "  label                              DT_max_dp_cnts  \\\n",
       "0   CHN     [4, 6, 6, 8, 8, 5, 4, 6, 8, 4, 5, 7, 6]   \n",
       "1   CHN  [7, 4, 4, 3, 5, 5, 5, 5, 4, 6, 6, 7, 8, 9]   \n",
       "\n",
       "                                            DT_archs  \\\n",
       "0  [nsubj ROOT mark nsubj ccomp acomp mark compou...   \n",
       "1  [aux det amod npadvmod punct compound nsubj ac...   \n",
       "\n",
       "                                    DT_ROOT_idx  \\\n",
       "0     [1, 9, 3, 16, 8, 8, 1, 3, 7, 1, 11, 2, 4]   \n",
       "1  [13, 2, 2, 1, 3, 6, 8, 5, 2, 3, 2, 4, 11, 4]   \n",
       "\n",
       "                                  DT_pass_cnt  \\\n",
       "0     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "1  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1]   \n",
       "\n",
       "                                  DT_mark_cnt  \\\n",
       "0     [2, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0]   \n",
       "1  [0, 2, 0, 0, 1, 0, 1, 0, 0, 2, 0, 0, 1, 0]   \n",
       "\n",
       "                                       POS_adjv_body  \\\n",
       "0  [apart, nowadays, large, well, many, when, the...   \n",
       "1  [last, very, big, many, firstly, most, importa...   \n",
       "\n",
       "                                              DT_pos  \\\n",
       "0  [NOUN VERB ADP PRON VERB ADJ ADP NOUN NOUN PAR...   \n",
       "1  [VERB DET ADJ NOUN PUNCT NOUN NOUN VERB DET AD...   \n",
       "\n",
       "                                         DT_pos_join  \\\n",
       "0  NOUN VERB ADP PRON VERB ADJ ADP NOUN NOUN PART...   \n",
       "1  VERB DET ADJ NOUN PUNCT NOUN NOUN VERB DET ADJ...   \n",
       "\n",
       "                                       DT_archs_join  unique_lemma  \\\n",
       "0  nsubj ROOT mark nsubj ccomp acomp mark compoun...            94   \n",
       "1  aux det amod npadvmod punct compound nsubj acl...           100   \n",
       "\n",
       "   avg_stc_length  total_stc  \n",
       "0       19.538462         13  \n",
       "1       16.714286         14  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_0.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make classes balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy.random import choice\n",
    "cond = (df_0['label']=='CHN')\n",
    "idx_remove = list(choice(df_0[cond].index, 400, replace=False))\n",
    "cond = (df_0['label']=='JPN')\n",
    "idx_remove += list(choice(df_0[cond].index, 400, replace=False))\n",
    "cond = (df_0['label']=='KOR')\n",
    "idx_remove += list(choice(df_0[cond].index, 200, replace=False))\n",
    "cond = (df_0['label']=='THA')&(df_0['avg_stc_length']<31)\n",
    "idx_remove += list(choice(df_0[cond].index, 400, replace=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1400"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(idx_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#idx_remove\n",
    "df_1 = df_0.drop(df_0.index[idx_remove])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAD3CAYAAADi8sSvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSSqIpS5JBbHUJakg/wQSlK63IZlszgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10e843150>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "countries = list(df_1.groupby('label').size().index)\n",
    "sample_count = df_1.groupby('label').size().values\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(range(len(countries)), sample_count)\n",
    "#ax.xticks = countries\n",
    "plt.xticks(range(len(countries)), countries)\n",
    "#fig.set_size_inches(18.5, 10.5, forward=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using only simple numeric essay statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df_1[['unique_lemma','avg_stc_length','total_stc']]\n",
    "y = df_1['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.266864963575\n"
     ]
    }
   ],
   "source": [
    "pipeline_lgr = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', LogisticRegression())\n",
    "])\n",
    "scores = cross_val_score(pipeline_lgr, X_train, y_train, cv=11, scoring='accuracy')\n",
    "print scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline_lgr.fit(X_train, y_train)\n",
    "y_pred = pipeline_lgr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>CHN</th>\n",
       "      <th>ENS</th>\n",
       "      <th>IDN</th>\n",
       "      <th>JPN</th>\n",
       "      <th>KOR</th>\n",
       "      <th>PAK</th>\n",
       "      <th>PHL</th>\n",
       "      <th>SIN</th>\n",
       "      <th>THA</th>\n",
       "      <th>All</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CHN</th>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>0.295455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENS</th>\n",
       "      <td>7</td>\n",
       "      <td>81</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>113</td>\n",
       "      <td>0.716814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IDN</th>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>41</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>110</td>\n",
       "      <td>0.027273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JPN</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>49</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>0.510417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KOR</th>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>9</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>103</td>\n",
       "      <td>0.087379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAK</th>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>97</td>\n",
       "      <td>0.247423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PHL</th>\n",
       "      <td>24</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>88</td>\n",
       "      <td>0.113636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SIN</th>\n",
       "      <td>13</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>0.262136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>THA</th>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>102</td>\n",
       "      <td>0.098039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>129</td>\n",
       "      <td>197</td>\n",
       "      <td>36</td>\n",
       "      <td>222</td>\n",
       "      <td>36</td>\n",
       "      <td>116</td>\n",
       "      <td>48</td>\n",
       "      <td>84</td>\n",
       "      <td>32</td>\n",
       "      <td>900</td>\n",
       "      <td>0.265556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted  CHN  ENS  IDN  JPN  KOR  PAK  PHL  SIN  THA  All  Accuracy\n",
       "Actual                                                               \n",
       "CHN         26    4    7   17    7   11    5   11    0   88  0.295455\n",
       "ENS          7   81    2    2    0    3    2   16    0  113  0.716814\n",
       "IDN          9   15    3   41    7   11    6    6   12  110  0.027273\n",
       "JPN          8    1    4   49    6   24    3    0    1   96  0.510417\n",
       "KOR         12   11    2   32    9   21    5    8    3  103  0.087379\n",
       "PAK         19    5    4   35    3   24    3    3    1   97  0.247423\n",
       "PHL         24   22    2   12    0    4   10   10    4   88  0.113636\n",
       "SIN         13   40    3    2    1    4   12   27    1  103  0.262136\n",
       "THA         11   18    9   32    3   14    2    3   10  102  0.098039\n",
       "All        129  197   36  222   36  116   48   84   32  900  0.265556"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwk.print_confusion_matrix(y_test.values, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.249726112799\n"
     ]
    }
   ],
   "source": [
    "# Skipping gridsearch for now since this is just basic model exploration\n",
    "pipeline_rf = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', RandomForestClassifier(n_estimators=100))\n",
    "])\n",
    "scores = cross_val_score(pipeline_rf, X_train, y_train, cv=11)\n",
    "print scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_2 = df_1\n",
    "df_2['DT_max_dp_cnts_std'] = df_2['DT_max_dp_cnts'].apply(lambda x: np.std(x))\n",
    "df_2['DT_ROOT_idx_mean'] = df_2['DT_ROOT_idx'].apply(lambda x: np.mean(x))\n",
    "df_2['DT_pass_cnt_sum'] = df_2['DT_pass_cnt'].apply(lambda x: np.sum(x))\n",
    "df_2['DT_mark_cnt_sum'] = df_2['DT_mark_cnt'].apply(lambda x: np.sum(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = ['DT_max_dp_cnts_std','DT_ROOT_idx_mean','DT_mark_cnt_sum']\n",
    "X = df_2[cols]\n",
    "y = df_2['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.202276834594\n"
     ]
    }
   ],
   "source": [
    "pipeline_lgr = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', LogisticRegression())\n",
    "])\n",
    "scores = cross_val_score(pipeline_lgr, X_train, y_train, cv=11, scoring='accuracy')\n",
    "print scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline_lgr.fit(X_train, y_train)\n",
    "y_pred = pipeline_lgr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>CHN</th>\n",
       "      <th>ENS</th>\n",
       "      <th>JPN</th>\n",
       "      <th>KOR</th>\n",
       "      <th>PAK</th>\n",
       "      <th>PHL</th>\n",
       "      <th>SIN</th>\n",
       "      <th>THA</th>\n",
       "      <th>IDN</th>\n",
       "      <th>All</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CHN</th>\n",
       "      <td>38</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>106</td>\n",
       "      <td>0.358491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENS</th>\n",
       "      <td>19</td>\n",
       "      <td>45</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "      <td>0.441176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IDN</th>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JPN</th>\n",
       "      <td>17</td>\n",
       "      <td>26</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>105</td>\n",
       "      <td>0.152381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KOR</th>\n",
       "      <td>19</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>0.050505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAK</th>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>63</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>0.656250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PHL</th>\n",
       "      <td>22</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>0.034091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SIN</th>\n",
       "      <td>21</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "      <td>0.164835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>THA</th>\n",
       "      <td>14</td>\n",
       "      <td>18</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>106</td>\n",
       "      <td>0.028302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>173</td>\n",
       "      <td>218</td>\n",
       "      <td>105</td>\n",
       "      <td>52</td>\n",
       "      <td>236</td>\n",
       "      <td>31</td>\n",
       "      <td>53</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>900</td>\n",
       "      <td>0.208889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted  CHN  ENS  JPN  KOR  PAK  PHL  SIN  THA  IDN  All  Accuracy\n",
       "Actual                                                               \n",
       "CHN         38   23    7   10   14    3    6    5    0  106  0.358491\n",
       "ENS         19   45   11    5    4    3    6    9    0  102  0.441176\n",
       "IDN         20   22   21    6   24    4    9    1    0  107  0.000000\n",
       "JPN         17   26   16    7   33    3    1    2    0  105  0.152381\n",
       "KOR         19   16   10    5   38    2    5    4    0   99  0.050505\n",
       "PAK          3   13    8    5   63    3    0    1    0   96  0.656250\n",
       "PHL         22   25    6    8   15    3    8    1    0   88  0.034091\n",
       "SIN         21   30    2    3    7    7   15    6    0   91  0.164835\n",
       "THA         14   18   24    3   38    3    3    3    0  106  0.028302\n",
       "All        173  218  105   52  236   31   53   32    0  900  0.208889"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwk.print_confusion_matrix(y_test.values, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS tagging and syntactic tree parsing features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'doc_id', u'path', u'author_code', u'essay_content', u'label',\n",
       "       u'DT_max_dp_cnts', u'DT_archs', u'DT_ROOT_idx', u'DT_pass_cnt',\n",
       "       u'DT_mark_cnt', u'POS_adjv_body', u'DT_pos', u'DT_pos_join',\n",
       "       u'DT_archs_join', u'unique_lemma', u'avg_stc_length', u'total_stc',\n",
       "       u'POS_adjv_repeat', u'POS_adjv_repeat_sum', u'doc2vec_lm_token',\n",
       "       u'DT_max_dp_cnts_std', u'DT_ROOT_idx_mean', u'DT_pass_cnt_sum',\n",
       "       u'DT_mark_cnt_sum'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate tf/tf-idf matrix on pos tag body for essays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df_2.DT_pos_join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df_2['DT_pos_join']\n",
    "y = df_2['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.55305832145\n"
     ]
    }
   ],
   "source": [
    "pipeline_lgr = Pipeline([\n",
    "    ('vect', TfidfVectorizer(lowercase=True, ngram_range=(2,2), max_features=100)),\n",
    "    ('clf', LogisticRegression())\n",
    "])\n",
    "scores = cross_val_score(pipeline_lgr, X_train, y_train, cv=11, scoring='accuracy')\n",
    "print scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>CHN</th>\n",
       "      <th>ENS</th>\n",
       "      <th>IDN</th>\n",
       "      <th>JPN</th>\n",
       "      <th>KOR</th>\n",
       "      <th>PAK</th>\n",
       "      <th>PHL</th>\n",
       "      <th>SIN</th>\n",
       "      <th>THA</th>\n",
       "      <th>All</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CHN</th>\n",
       "      <td>53</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>108</td>\n",
       "      <td>0.490741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENS</th>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>105</td>\n",
       "      <td>0.628571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IDN</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>37</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>91</td>\n",
       "      <td>0.406593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JPN</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>68</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>105</td>\n",
       "      <td>0.647619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KOR</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>97</td>\n",
       "      <td>0.329897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAK</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>97</td>\n",
       "      <td>0.773196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PHL</th>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>42</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>108</td>\n",
       "      <td>0.388889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SIN</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>67</td>\n",
       "      <td>2</td>\n",
       "      <td>91</td>\n",
       "      <td>0.736264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>THA</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>47</td>\n",
       "      <td>98</td>\n",
       "      <td>0.479592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>89</td>\n",
       "      <td>106</td>\n",
       "      <td>80</td>\n",
       "      <td>128</td>\n",
       "      <td>64</td>\n",
       "      <td>131</td>\n",
       "      <td>71</td>\n",
       "      <td>130</td>\n",
       "      <td>101</td>\n",
       "      <td>900</td>\n",
       "      <td>0.541111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted  CHN  ENS  IDN  JPN  KOR  PAK  PHL  SIN  THA  All  Accuracy\n",
       "Actual                                                               \n",
       "CHN         53    4    8   13    7    4    2   11    6  108  0.490741\n",
       "ENS          3   66    1    2    2    4    5   18    4  105  0.628571\n",
       "IDN          4    3   37    7    4   15    5    4   12   91  0.406593\n",
       "JPN          5    3    3   68    9    5    1    3    8  105  0.647619\n",
       "KOR          7    2   10   21   32    4    1    9   11   97  0.329897\n",
       "PAK          1    3    6    0    0   75    5    0    7   97  0.773196\n",
       "PHL          9   13   11    6    0    9   42   14    4  108  0.388889\n",
       "SIN          2    7    1    4    1    2    5   67    2   91  0.736264\n",
       "THA          5    5    3    7    9   13    5    4   47   98  0.479592\n",
       "All         89  106   80  128   64  131   71  130  101  900  0.541111"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_lgr.fit(X_train, y_train)\n",
    "y_pred = pipeline_lgr.predict(X_test)\n",
    "pwk.print_confusion_matrix(y_test.values, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pos ngram with sentence boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 4\n",
    "df_2['DT_insent_pos_ngram'] = df_2['DT_pos'].apply(lambda x: pwk.loop_body(x, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df_2['DT_insent_pos_ngram']\n",
    "y = df_2['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.646561952902\n"
     ]
    }
   ],
   "source": [
    "pipeline_lgr = Pipeline([\n",
    "    ('vect', TfidfVectorizer(lowercase=True, max_features=5000)),\n",
    "    ('clf', LogisticRegression())\n",
    "])\n",
    "scores = cross_val_score(pipeline_lgr, X_train, y_train, cv=11, scoring='accuracy')\n",
    "print scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**arch ngram with sentence boundary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 3\n",
    "df_2['DT_insent_arch_ngram'] = df_2['DT_archs'].apply(lambda x: pwk.loop_body(x, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df_2['DT_insent_arch_ngram']\n",
    "y = df_2['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.68889757809\n"
     ]
    }
   ],
   "source": [
    "pipeline_lgr = Pipeline([\n",
    "    ('vect', TfidfVectorizer(lowercase=True, max_features=5000)),\n",
    "    ('clf', LogisticRegression())#solver='newton-cg', multi_class='multinomial'))\n",
    "])\n",
    "scores = cross_val_score(pipeline_lgr, X_train, y_train, cv=11, scoring='accuracy')\n",
    "print scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>CHN</th>\n",
       "      <th>ENS</th>\n",
       "      <th>IDN</th>\n",
       "      <th>JPN</th>\n",
       "      <th>KOR</th>\n",
       "      <th>PAK</th>\n",
       "      <th>PHL</th>\n",
       "      <th>SIN</th>\n",
       "      <th>THA</th>\n",
       "      <th>All</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CHN</th>\n",
       "      <td>79</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>106</td>\n",
       "      <td>0.745283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENS</th>\n",
       "      <td>2</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>102</td>\n",
       "      <td>0.696078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IDN</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>61</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>107</td>\n",
       "      <td>0.570093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JPN</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>105</td>\n",
       "      <td>0.809524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KOR</th>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>99</td>\n",
       "      <td>0.424242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAK</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>96</td>\n",
       "      <td>0.864583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PHL</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>47</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>88</td>\n",
       "      <td>0.534091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SIN</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "      <td>0.813187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>THA</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>106</td>\n",
       "      <td>0.603774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>111</td>\n",
       "      <td>99</td>\n",
       "      <td>101</td>\n",
       "      <td>118</td>\n",
       "      <td>68</td>\n",
       "      <td>108</td>\n",
       "      <td>83</td>\n",
       "      <td>124</td>\n",
       "      <td>88</td>\n",
       "      <td>900</td>\n",
       "      <td>0.673333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted  CHN  ENS  IDN  JPN  KOR  PAK  PHL  SIN  THA  All  Accuracy\n",
       "Actual                                                               \n",
       "CHN         79    2    3   10    4    1    4    3    0  106  0.745283\n",
       "ENS          2   71    0    0    0    1    5   21    2  102  0.696078\n",
       "IDN          5    6   61    3    3    8   11    2    8  107  0.570093\n",
       "JPN          2    1    1   85   10    2    1    0    3  105  0.809524\n",
       "KOR         11    5    9   12   42    4    5    5    6   99  0.424242\n",
       "PAK          3    1    3    0    1   83    1    0    4   96  0.864583\n",
       "PHL          4    3    7    0    3    6   47   17    1   88  0.534091\n",
       "SIN          3    6    1    0    1    0    6   74    0   91  0.813187\n",
       "THA          2    4   16    8    4    3    3    2   64  106  0.603774\n",
       "All        111   99  101  118   68  108   83  124   88  900  0.673333"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_lgr.fit(X_train, y_train)\n",
    "y_pred = pipeline_lgr.predict(X_test)\n",
    "pwk.print_confusion_matrix(y_test.values, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jpn_kor = df_2[(df_2['label']=='JPN')|(df_2['label']=='KOR')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_jpn_kor['DT_insent_pos_ngram']\n",
    "y = df_jpn_kor['label'].values=='JPN'\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(lowercase=True, max_features=30)\n",
    "X_train_dtm = vectorizer.fit_transform(X_train)\n",
    "X_test_dtm = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "terms = np.array(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, 30)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "      <th>All</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>41</td>\n",
       "      <td>39</td>\n",
       "      <td>80</td>\n",
       "      <td>0.5125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>25</td>\n",
       "      <td>55</td>\n",
       "      <td>80</td>\n",
       "      <td>0.6875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>66</td>\n",
       "      <td>94</td>\n",
       "      <td>160</td>\n",
       "      <td>0.6000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted  False  True  All  Accuracy\n",
       "Actual                               \n",
       "False         41    39   80    0.5125\n",
       "True          25    55   80    0.6875\n",
       "All           66    94  160    0.6000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(X_train_dtm, y_train)\n",
    "y_pred = clf.predict(X_test_dtm)\n",
    "pwk.print_confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The top 10 most representive word orders of PAK**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([u'adp_adj_noun_punct', u'noun_verb_det_noun', u'noun_verb_adv_adj',\n",
       "       u'noun_adp_adj_noun', u'noun_adp_noun_punct', u'det_noun_adp_noun',\n",
       "       u'verb_adj_noun_punct', u'verb_adj_noun_adp', u'adp_det_noun_punct',\n",
       "       u'det_adj_noun_punct'], \n",
       "      dtype='<U19')"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms[np.argsort(clf.coef_[0])[::-1][:10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The top 10 most representive word orders of ENS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([u'adj_punct_noun_noun', u'pron_verb_adv_verb', u'adp_det_adj_noun',\n",
       "       u'det_adj_noun_adp', u'verb_adp_det_noun', u'noun_verb_adv_verb',\n",
       "       u'verb_det_adj_noun', u'adv_verb_det_noun', u'adj_noun_adp_det',\n",
       "       u'part_verb_det_noun'], \n",
       "      dtype='<U19')"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms[np.argsort(clf.coef_[0])[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "#df_ens_pak[df_ens_pak['label']=='PAK'][['essay_content','DT_pos']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df_ens_pak['xxx'] = df_ens_pak[['essay_content','DT_pos']].apply(lambda x: [s+p for s,p in zip(spc_nlp(x[0].decode('utf-8')).sents, x[1])])\n",
    "df_ens_pak['essay_pos'] = df_ens_pak[['essay_content','DT_pos']].apply(lambda x: [s.text+p for s,p in zip(spc_nlp(x['essay_content'].decode('utf-8')).sents, x['DT_pos'])], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_ens_pak[df_ens_pak['label']=='PAK']['essay_pos'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Concat features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'doc_id', u'path', u'author_code', u'essay_content', u'label',\n",
       "       u'DT_max_dp_cnts', u'DT_archs', u'DT_ROOT_idx', u'DT_pass_cnt',\n",
       "       u'DT_mark_cnt', u'POS_adjv_body', u'DT_pos', u'DT_pos_join',\n",
       "       u'DT_archs_join', u'unique_lemma', u'avg_stc_length', u'total_stc',\n",
       "       u'POS_adjv_repeat', u'POS_adjv_repeat_sum', u'doc2vec_lm_token',\n",
       "       u'DT_max_dp_cnts_std', u'DT_ROOT_idx_mean', u'DT_pass_cnt_sum',\n",
       "       u'DT_mark_cnt_sum', u'DT_insent_arch_ngram', u'DT_insent_pos_ngram'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_jpn_kor.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df_jpn_kor[['DT_insent_pos_ngram','unique_lemma','avg_stc_length']]\n",
    "y = df_jpn_kor['label'].values=='JPN'\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8)\n",
    "\n",
    "# vectorizer = TfidfVectorizer(lowercase=True, max_features=100)\n",
    "# X_train_dtm = vectorizer.fit_transform(X_train)\n",
    "# X_test_dtm = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "vectorizer = TfidfVectorizer(lowercase=True, max_features=100).fit(X_train)\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32) \n",
    "\n",
    "df_all_train = sp.sparse.hstack((vectorizer.transform(X_train['DT_insent_pos_ngram']),X_train[['unique_lemma','avg_stc_length']].values),format='csr')\n",
    "df_all_test = sp.sparse.hstack((vectorizer.transform(X_test['DT_insent_pos_ngram']),X_test[['unique_lemma','avg_stc_length']].values),format='csr')\n",
    "\n",
    "df_all_columns=vectorizer.get_feature_names()+X[['unique_lemma','avg_stc_length']].columns.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 94.,  10.])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[['unique_lemma','avg_stc_length']].values[0]\n",
    "#df_all_train.todense()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = sp.sparse.hstack((vectorizer.fit_transform(X_train['DT_insent_pos_ngram'])[0],X_train[['unique_lemma','avg_stc_length']][:1].values),format='csr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfx = pd.DataFrame(a.todense(), columns=df_all_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adj_adp_noun_noun</th>\n",
       "      <th>adj_noun_adp_noun</th>\n",
       "      <th>adj_noun_part_verb</th>\n",
       "      <th>adj_noun_verb_verb</th>\n",
       "      <th>adj_punct_noun_noun</th>\n",
       "      <th>adp_adj_det_noun</th>\n",
       "      <th>adp_adj_noun_punct</th>\n",
       "      <th>adp_det_adj_noun</th>\n",
       "      <th>adp_det_noun_adp</th>\n",
       "      <th>adp_det_noun_noun</th>\n",
       "      <th>...</th>\n",
       "      <th>verb_det_noun_punct</th>\n",
       "      <th>verb_noun_adp_noun</th>\n",
       "      <th>verb_noun_punct_noun</th>\n",
       "      <th>verb_part_verb_det</th>\n",
       "      <th>verb_verb_adj_noun</th>\n",
       "      <th>verb_verb_adp_det</th>\n",
       "      <th>verb_verb_adp_noun</th>\n",
       "      <th>verb_verb_det_noun</th>\n",
       "      <th>unique_lemma</th>\n",
       "      <th>avg_stc_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.105159</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125682</td>\n",
       "      <td>0.163969</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.270675</td>\n",
       "      <td>0.134452</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   adj_adp_noun_noun  adj_noun_adp_noun  adj_noun_part_verb  \\\n",
       "0                0.0                0.0                 0.0   \n",
       "\n",
       "   adj_noun_verb_verb  adj_punct_noun_noun  adp_adj_det_noun  \\\n",
       "0                 0.0                  0.0               0.0   \n",
       "\n",
       "   adp_adj_noun_punct  adp_det_adj_noun  adp_det_noun_adp  adp_det_noun_noun  \\\n",
       "0                 0.0               0.0          0.105159                0.0   \n",
       "\n",
       "        ...        verb_det_noun_punct  verb_noun_adp_noun  \\\n",
       "0       ...                        0.0            0.125682   \n",
       "\n",
       "   verb_noun_punct_noun  verb_part_verb_det  verb_verb_adj_noun  \\\n",
       "0              0.163969                 0.0                 0.0   \n",
       "\n",
       "   verb_verb_adp_det  verb_verb_adp_noun  verb_verb_det_noun  unique_lemma  \\\n",
       "0           0.270675            0.134452                 0.0          94.0   \n",
       "\n",
       "   avg_stc_length  \n",
       "0            10.0  \n",
       "\n",
       "[1 rows x 102 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc2Vec matrix featurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorize: essay_content, DT_insent_arch_ngram, DT_insent_pos_ngram, DT_arch_join, DT_pos_join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 5\n",
    "df_2['DT_insent_arch_ngram'] = df_2['DT_archs'].apply(lambda x: pwk.loop_body(x, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 5\n",
    "df_2['DT_insent_pos_ngram'] = df_2['DT_pos'].apply(lambda x: pwk.loop_body(x, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cond = (df_2['label']!='ENS')|(df_2['label']!='CHN')|\\\n",
    "(df_2['label']!='JPN')|(df_2['label']!='KOR')|(df_2['label']!='THA')\n",
    "df_input = df_2[cond]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv_data, test_data = train_test_split(df_input, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cross validation using different classifiers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "ngram_range = [i for i in range(2,11)]\n",
    "window_range = [i for i in range(1,6)]\n",
    "\n",
    "combs = list(itertools.product(ngram_range, window_range))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col = 'essay_content'\n",
    "# essay_content, DT_insent_arch_ngram, DT_insent_pos_ngram, DT_arch_join, DT_pos_join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use all possible combinations of ngram and window size to see performance differences**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col = 'essay_content'\n",
    "for w in range(1,10):\n",
    "    print ('window size: ', w)\n",
    "    cond = (df_2['label']!='ENS')|(df_2['label']!='CHN')|\\\n",
    "    (df_2['label']!='JPN')|(df_2['label']!='KOR')|(df_2['label']!='THA')\n",
    "    df_input = df_2[cond]\n",
    "    cv_data, test_data = train_test_split(df_input, test_size=0.1)\n",
    "    clf = LogisticRegression()\n",
    "    print (pwk.k_fold_doc2vec_clf(cv_data, col, w, 100, clf, literal=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col = 'DT_arch_join'\n",
    "for w in range(1,10):\n",
    "    print ('window size: ', w)\n",
    "    cond = (df_2['label']!='ENS')|(df_2['label']!='CHN')|\\\n",
    "    (df_2['label']!='JPN')|(df_2['label']!='KOR')|(df_2['label']!='THA')\n",
    "    df_input = df_2[cond]\n",
    "    cv_data, test_data = train_test_split(df_input, test_size=0.1)\n",
    "    clf = LogisticRegression()\n",
    "    print (pwk.k_fold_doc2vec_clf(cv_data, col, w, 100, clf, literal=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col = 'DT_pos_join'\n",
    "for w in range(1,10):\n",
    "    print ('window size: ', w)\n",
    "    cond = (df_2['label']!='ENS')|(df_2['label']!='CHN')|\\\n",
    "    (df_2['label']!='JPN')|(df_2['label']!='KOR')|(df_2['label']!='THA')\n",
    "    df_input = df_2[cond]\n",
    "    cv_data, test_data = train_test_split(df_input, test_size=0.1)\n",
    "    clf = LogisticRegression()\n",
    "    print (pwk.k_fold_doc2vec_clf(cv_data, col, w, 100, clf, literal=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col = 'DT_insent_pos_ngram'\n",
    "for ng in range(2, 21):\n",
    "    print ('ngram_n: ', ng)\n",
    "    #print ('window size: ', c[1])\n",
    "    print ('window size: ', str(1))\n",
    "    n = ng\n",
    "    df_2['DT_insent_pos_ngram'] = df_2['DT_pos'].apply(lambda x: pwk.loop_body(x, n))\n",
    "    cond = (df_2['label']!='ENS')|(df_2['label']!='CHN')|\\\n",
    "    (df_2['label']!='JPN')|(df_2['label']!='KOR')|(df_2['label']!='THA')\n",
    "    df_input = df_2[cond]\n",
    "    cv_data, test_data = train_test_split(df_input, test_size=0.1)\n",
    "    clf = LogisticRegression()\n",
    "    print (pwk.k_fold_doc2vec_clf(cv_data, col, 1, 100, clf, literal=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col = 'DT_insent_arch_ngram'\n",
    "for ng in range(2, 21):\n",
    "    print ('ngram_n: ', ng)\n",
    "    #print ('window size: ', c[1])\n",
    "    print ('window size: ', str(1))\n",
    "    n = ng\n",
    "    df_2['DT_insent_arch_ngram'] = df_2['DT_archs'].apply(lambda x: pwk.loop_body(x, n))\n",
    "    cond = (df_2['label']!='ENS')|(df_2['label']!='CHN')|\\\n",
    "    (df_2['label']!='JPN')|(df_2['label']!='KOR')|(df_2['label']!='THA')\n",
    "    df_input = df_2[cond]\n",
    "    cv_data, test_data = train_test_split(df_input, test_size=0.1)\n",
    "    clf = LogisticRegression()\n",
    "    print (pwk.k_fold_doc2vec_clf(cv_data, col, 1, 100, clf, literal=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pick the best hyper patameter and model for final train and test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(df_2, test_size=0.7)\n",
    "\n",
    "col = 'essay_content'\n",
    "train_docs = pwk.tag_docs(train_data, col, literal=True)\n",
    "test_docs = pwk.tag_docs(test_data, col, literal=True)\n",
    "model = pwk.train_doc2vec_model(train_docs, 2, 100)\n",
    "    \n",
    "y_train, X_train = pwk.vec_for_learning(model, train_docs)\n",
    "y_test, X_test = pwk.vec_for_learning(model, test_docs)\n",
    "    \n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.788\n"
     ]
    }
   ],
   "source": [
    "print accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>CHN</th>\n",
       "      <th>ENS</th>\n",
       "      <th>IDN</th>\n",
       "      <th>JPN</th>\n",
       "      <th>KOR</th>\n",
       "      <th>PAK</th>\n",
       "      <th>PHL</th>\n",
       "      <th>SIN</th>\n",
       "      <th>THA</th>\n",
       "      <th>All</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CHN</th>\n",
       "      <td>225</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>278</td>\n",
       "      <td>0.809353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENS</th>\n",
       "      <td>0</td>\n",
       "      <td>222</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "      <td>283</td>\n",
       "      <td>0.784452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IDN</th>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>200</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>280</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JPN</th>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>221</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>277</td>\n",
       "      <td>0.797834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KOR</th>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>179</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>278</td>\n",
       "      <td>0.643885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAK</th>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>242</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>260</td>\n",
       "      <td>0.930769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PHL</th>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>201</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>292</td>\n",
       "      <td>0.688356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SIN</th>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>224</td>\n",
       "      <td>0</td>\n",
       "      <td>285</td>\n",
       "      <td>0.785965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>THA</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>191</td>\n",
       "      <td>287</td>\n",
       "      <td>0.665505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>288</td>\n",
       "      <td>315</td>\n",
       "      <td>248</td>\n",
       "      <td>282</td>\n",
       "      <td>270</td>\n",
       "      <td>292</td>\n",
       "      <td>283</td>\n",
       "      <td>288</td>\n",
       "      <td>254</td>\n",
       "      <td>2520</td>\n",
       "      <td>0.755952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted  CHN  ENS  IDN  JPN  KOR  PAK  PHL  SIN  THA   All  Accuracy\n",
       "Actual                                                                \n",
       "CHN        225    7    4   10   15    7    3    0    7   278  0.809353\n",
       "ENS          0  222    3    2   10    3    9   27    7   283  0.784452\n",
       "IDN          3   13  200    9   10    9   17    7   12   280  0.714286\n",
       "JPN         15    7    6  221   17    6    1    1    3   277  0.797834\n",
       "KOR         17    5    5   22  179    8   12    5   25   278  0.643885\n",
       "PAK          9    3    1    0    1  242    2    1    1   260  0.930769\n",
       "PHL          4   26   11    2   12   12  201   16    8   292  0.688356\n",
       "SIN          6   22    1    2    6    2   22  224    0   285  0.785965\n",
       "THA          9   10   17   14   20    3   16    7  191   287  0.665505\n",
       "All        288  315  248  282  270  292  283  288  254  2520  0.755952"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwk.print_confusion_matrix(y_test, y_pred)#['All']['All']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Combining all features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gridsearch on Doc2Vec feature (done on AWS EC2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_data, test_data = train_test_split(df_2, test_size=0.7)\n",
    "\n",
    "# col = 'essay_content'\n",
    "# train_docs = pwk.tag_docs(train_data, col, literal=True)\n",
    "# test_docs = pwk.tag_docs(test_data, col, literal=True)\n",
    "# model = pwk.train_doc2vec_model(train_docs, 2, 100)\n",
    "\n",
    "# y_train, X_train = pwk.vec_for_learning(model, train_docs)\n",
    "# y_test, X_test = pwk.vec_for_learning(model, test_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model = ('lrclf', LogisticRegression())\n",
    "\n",
    "# steps = [\n",
    "#     model\n",
    "# ]\n",
    "\n",
    "# grid = {'lrclf__C':[0.001,0.01,0.1,1,10],\n",
    "#         'lrclf__penalty':['l1','l2']\n",
    "# }\n",
    "\n",
    "# pipeline = Pipeline(steps)\n",
    "# gridsearch = GridSearchCV(pipeline,\n",
    "#                           grid,\n",
    "#                           scoring='accuracy',\n",
    "#                           cv=5,\n",
    "#                           verbose=1,\n",
    "#                           n_jobs=-1)\n",
    "\n",
    "# gridsearch.fit(X_train, y_train)\n",
    "# best_model = gridsearch.best_estimator_\n",
    "# print (best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clf = LogisticRegression(penalty='l2', C=1)\n",
    "# clf.fit(X_train, y_train)\n",
    "# y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pwk.print_confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model = ('rfclf', RandomForestClassifier())\n",
    "\n",
    "# steps = [\n",
    "#     model\n",
    "# ]\n",
    "# random_forest_grid = {'rfclf__max_depth': [None, 2, 3, 4],\n",
    "#                       'rfclf__max_features': ['sqrt', 'log2', None],\n",
    "#                       'rfclf__min_samples_split': [2, 3, 4],\n",
    "#                       'rfclf__min_samples_leaf': [1, 2, 3,4],\n",
    "#                       'rfclf__criterion': ['gini', 'entropy'],\n",
    "#                       'rfclf__bootstrap': [True, False],\n",
    "#                       'rfclf__n_estimators': [10000]}\n",
    "\n",
    "# pipeline = Pipeline(steps)\n",
    "# gridsearch = GridSearchCV(pipeline,\n",
    "#                          random_forest_grid,\n",
    "#                          n_jobs=-1,\n",
    "#                          cv=5,\n",
    "#                          verbose=1,\n",
    "#                          scoring='accuracy')\n",
    "\n",
    "# gridsearch.fit(X_train, y_train)\n",
    "# best_rf_model = gridsearch.best_estimator_\n",
    "# print (best_rf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clf = RandomForestClassifier(XXX)\n",
    "# clf.fit(X_train, y_train)\n",
    "# y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pwk.print_confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# gradient_boosting_grid = {'learning_rate': [0.1, 0.05, 0.02],\n",
    "#                           'loss': ['deviance', 'exponential'],\n",
    "#                           'max_depth': [2, 4],\n",
    "#                           'min_samples_leaf': [1, 2, 5],\n",
    "#                           'max_features': [1.0, 0.5],\n",
    "#                           'n_estimators': [500, 1000, 3000],\n",
    "#                           'random_state': [1]}\n",
    "\n",
    "# gbclf_gridsearch = GridSearchCV(GradientBoostingClassifier(), \n",
    "#                               gradient_boosting_grid,\n",
    "#                               cv=5,\n",
    "#                               verbose=5,\n",
    "#                               n_jobs=-1,\n",
    "#                               scoring='accuracy')\n",
    "# gbclf_gridsearch.fit(X_train, y_train)\n",
    "# print (\"best parameters:\", gbclf_gridsearch.best_params_)\n",
    "\n",
    "# best_gbclf_model = gbclf_gridsearch.best_estimator_\n",
    "# print best_gbclf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clf = GradientBoostingClassifier(n_estimators=XXX)\n",
    "# clf.fit(X_train, y_train)\n",
    "# y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pwk.print_confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english').fit(X_train)\n",
    "\n",
    "get_feture_name()....\n",
    "\n",
    "X_train_dtm = pd.DataFrame(vectorizer.transform(X_train), columns = vectorizer.get...)\n",
    "X_test_dtm = vectorizer.transform(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
