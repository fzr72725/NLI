{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "sys.path.insert(0, '../src')\n",
    "import prework as pwk\n",
    "import string\n",
    "from time import time\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import recall_score, accuracy_score, precision_score, roc_auc_score\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0 = pd.read_pickle('../data/pickles/20180117_part_one.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**After gridsearch, window_size=2, hidden_nodes=100 turns out to be the best choice**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform feature 'essay_content'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(df_0, train_size=0.8)\n",
    "col = 'essay_content'\n",
    "train_docs = pwk.tag_docs(train_data, col)\n",
    "test_docs = pwk.tag_docs(test_data, col)\n",
    "model = pwk.train_doc2vec_model(train_docs, 2, 100)\n",
    "\n",
    "y_train, X_train = pwk.vec_for_learning(model, train_docs)\n",
    "y_test, X_test = pwk.vec_for_learning(model, test_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'agree,because,it,teaches,students,to,take,on,more,responsibility,gives,them,some,extra,income,and,allows,them,to,get,some,very,real,work,experience,it,is,important,that,students,learn,that,they,have,to,earn,sooner,or,later,and,think,that,having,part,time,job,gives,them,the,perfect,introduction,as,to,what,life,will,really,be,like,when,they,enter,their,new,jobs,on,full,time,basis,if,were,in,college,would,be,getting,as,many,part,time,jobs,that,could,squeeze,in,because,want,to,have,many,different,experiences,so,when,and,if,travel,have,more,than,one,set,of,skills,that,can,fall,back,on,if,need,to,get,some,type,of,job,while,away,guess,it,can,be,easy,though,because,with,all,the,study,and,all,and,loads,of,other,students,also,looking,for,part,time,jobs,it,must,get,frustrating,for,them,sometimes,then,again,though,if,they,experience,lot,of,problems,at,college,then,they,get,better,at,dealing,with,them,which,have,got,to,help,them,later,in,life,mean,because,they,have,faced,some,challenges,then,they,get,better,at,dealing,with,them,and,stronger,mentally'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "','.join(train_docs.values[0].words)#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ENS_1127'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# <label>_<doc_id>\n",
    "','.join(train_docs.values[0].tags)#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3.80351092e-03,  -2.26163208e-01,  -2.40365833e-01,\n",
       "        -7.46642053e-01,  -8.73783529e-02,   7.55064338e-02,\n",
       "        -6.81282207e-02,  -5.81557527e-02,   1.72942907e-01,\n",
       "         6.89861119e-01,  -1.24780133e-01,  -4.67391282e-01,\n",
       "        -6.81670129e-01,   3.07710399e-03,  -5.13115644e-01,\n",
       "         3.06478679e-01,   1.60836563e-01,   1.48783773e-01,\n",
       "         2.45504789e-02,  -1.33079425e-01,  -1.83911055e-01,\n",
       "        -8.24804306e-01,  -1.04266211e-01,   1.47078067e-01,\n",
       "         1.66241392e-01,  -1.55283630e-01,   2.25255966e-01,\n",
       "        -2.41942659e-01,  -1.82405040e-01,   1.06709227e-01,\n",
       "        -3.62052247e-02,  -4.31679815e-01,   1.35203779e-01,\n",
       "        -8.36766735e-02,   2.96481490e-01,  -3.69180858e-01,\n",
       "         4.46793199e-01,   9.09058377e-04,   3.23891312e-01,\n",
       "         3.47610712e-01,   1.63281243e-02,  -3.27956527e-01,\n",
       "        -8.94003212e-01,  -3.66845019e-02,  -3.19157362e-01,\n",
       "        -3.85363013e-01,  -8.09012949e-01,  -1.52627807e-02,\n",
       "         3.10770750e-01,  -1.18129507e-01,  -2.98942566e-01,\n",
       "        -6.79241866e-02,   2.15520993e-01,   3.27613741e-01,\n",
       "        -4.19927925e-01,  -8.82502735e-01,   1.46273702e-01,\n",
       "        -6.76190972e-01,  -1.91090614e-01,  -2.79401153e-01,\n",
       "        -2.28257433e-01,   4.28074971e-02,  -3.42111925e-05,\n",
       "        -3.78044158e-01,   2.66591430e-01,   4.11021888e-01,\n",
       "        -2.44558472e-02,  -3.60462785e-01,   1.06776886e-01,\n",
       "         4.98635709e-01,  -1.39007461e+00,   9.97745898e-03,\n",
       "        -3.37974578e-01,  -5.54998398e-01,  -7.88767636e-01,\n",
       "        -1.68471426e-01,   2.74377942e-01,   1.69049352e-02,\n",
       "        -4.86829996e-01,  -3.01119417e-01,   7.35718459e-02,\n",
       "        -1.71538964e-01,  -1.58142567e-01,  -1.39025763e-01,\n",
       "         3.82980049e-01,   1.17333196e-02,  -7.06757128e-01,\n",
       "         2.04643637e-01,   7.97217965e-01,   1.03100860e+00,\n",
       "        -1.32960641e+00,   4.89908546e-01,   1.36612177e-01,\n",
       "         6.39508963e-02,   6.13023937e-01,   3.89910579e-01,\n",
       "         3.72319738e-03,  -9.83835459e-02,  -1.94353342e-01,\n",
       "         6.21459544e-01], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ENS'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get a rough idea about how this vector is performing for classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.81770833333333337, 0.82465277777777779, 0.82118055555555558, 0.78645833333333337, 0.828125]\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = train_test_split(df_0, train_size=0.8)\n",
    "col = 'essay_content'\n",
    "\n",
    "clf = LogisticRegression()\n",
    "print pwk.k_fold_doc2vec_clf(train_data, col, 2, 100, clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform feature 'DT_insent_arch_ngram'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 4\n",
    "df_0['DT_insent_arch_ngram'] = df_0['DT_archs'].apply(lambda x: pwk.loop_body(x, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(df_0, train_size=0.8)\n",
    "col = 'DT_insent_arch_ngram'\n",
    "# train_docs = pwk.tag_docs(train_data, col, literal=False)\n",
    "# test_docs = pwk.tag_docs(test_data, col, literal=False)\n",
    "# model = pwk.train_doc2vec_model(train_docs, 1, 100)\n",
    "\n",
    "# y_train, X_train = pwk.vec_for_learning(model, train_docs)\n",
    "# y_test, X_test = pwk.vec_for_learning(model, test_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.36805555555555558, 0.35069444444444442, 0.3576388888888889, 0.34722222222222221, 0.37152777777777779]\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = train_test_split(df_0, train_size=0.8)\n",
    "col = 'DT_insent_arch_ngram'\n",
    "\n",
    "clf = LogisticRegression()\n",
    "print pwk.k_fold_doc2vec_clf(train_data, col, 1, 100, clf, literal=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Turns out 'essay_content' is the best-performing column for extracting the vector to classify essays.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
